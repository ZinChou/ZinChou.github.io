# **<u>搜广推面经大全</u>**





## 1. **双塔模型（Two-Tower Model）解析**

------

**1.1 什么是双塔模型？**

**双塔模型（Two-Tower Model）** 是 **深度学习推荐系统（DLRS）** 中的一种模型架构，广泛应用于：

- **推荐系统（Recommendation System）**
- **广告点击率预测（CTR Prediction）**
- **搜索排序（Ranking）**
- **用户匹配（Matching）**

**🎯 核心思想**

双塔模型将 **用户信息（User Tower）** 和 **物品信息（Item Tower）** 通过 **两个独立的神经网络** 进行特征提取，然后计算两者的相似度，以进行推荐或匹配。

✅ **核心目标：** 计算 **用户向量** 和 **物品向量** 之间的匹配度，实现高效召回。

------

**1.2 双塔模型的结构**

双塔模型的结构如下：

```
            ┌───────────────────────┐    ┌───────────────────────┐
            │     用户塔（User Tower）  │    │     物品塔（Item Tower） │
            │   （User Embedding）   │    │   （Item Embedding）  │
            └─────────────▲──────────┘    └─────────────▲──────────┘
                          │                              │
            ┌─────────────┴───────────────┐    ┌─────────────┴───────────────┐
            │ 用户特征（User Features）   │    │ 物品特征（Item Features）    │
            └────────────────────────────┘    └────────────────────────────┘
```

------

**🔹 (1) 用户塔（User Tower）**

- 负责将 **用户特征**（User Features）转换为 **用户向量（User Embedding）**。
- 可能的输入：用户 ID、性别、年龄、历史行为、兴趣标签等。
- 通过 **Embedding + MLP** 提取特征。

**🔹 (2) 物品塔（Item Tower）**

- 负责将 **物品特征**（Item Features）转换为 **物品向量（Item Embedding）**。
- 可能的输入：物品 ID、类别、品牌、标签、属性等。
- 通过 **Embedding + MLP** 提取特征。

**🔹 (3) 匹配（Matching）**

- 计算 

  用户向量和物品向量之间的相似度，常见方法：

  - **点积（Dot Product）**
  - **余弦相似度（Cosine Similarity）**
  - **欧几里得距离（Euclidean Distance）**

------









## **2. Batch Normalization vs. Layer Normalization：区别解析**

------

**1. Batch Normalization（BN） vs. Layer Normalization（LN）的核心区别**

| **对比项**               | **Batch Normalization（BN）**                          | **Layer Normalization（LN）**                                |
| ------------------------ | ------------------------------------------------------ | ------------------------------------------------------------ |
| **归一化维度**           | 在 **batch 维度** 归一化（同一通道上的不同样本归一化） | 在 **特征维度** 归一化（同一样本的所有特征归一化）           |
| **计算方式**             | 计算 **每个 mini-batch** 的均值和方差                  | 计算 **单个样本内部** 的均值和方差                           |
| **公式**                 | $\hat{x} = \frac{x - \mu_B}{\sigma_B}$                 | $\hat{x} = \frac{x - \mu_L}{\sigma_L}$                       |
| **适用场景**             | 适用于 **CNN（卷积网络）**，对 batch 变化敏感          | 适用于 **RNN（循环网络）和 Transformer**，适应不同 batch 大小 |
| **对 Batch Size 的依赖** | **依赖 batch size**，小 batch 可能不稳定               | **不依赖 batch size**，适用于小 batch 训练                   |
| **计算量**               | **额外计算 batch 统计量**，在推理时需存储均值和方差    | 计算更简单，无需额外存储 batch 统计量                        |
| **实现复杂度**           | 需要在训练时 **计算 batch 统计信息**，推理时用移动平均 | 直接计算单个样本的归一化，适用于分布式计算                   |
| **影响梯度传播**         | 影响 **batch 内样本之间的梯度**                        | 仅影响 **单个样本的梯度**，梯度计算更稳定                    |

------







## 3. **Batch Normalization（BN）训练和推理阶段的不同**

------

Batch Normalization（BN）在 **训练（Training）** 和 **推理（Inference）** 阶段的行为不同，主要体现在 **均值和方差计算方式** 上。这是因为在训练时，BN 依赖于 **mini-batch 统计信息**，而在推理时，模型需要使用 **全局统计信息** 来保持稳定性。

------

**3. 训练 vs. 推理的核心区别**

| **对比项**     | **训练阶段（Training）**                | **推理阶段（Inference）**                       |
| -------------- | --------------------------------------- | ----------------------------------------------- |
| **均值计算**   | **当前 batch 统计均值** $\mu_B$         | **全局移动平均均值** $\mu_{\text{global}}$      |
| **方差计算**   | **当前 batch 统计方差** $\sigma_B^2$    | **全局移动平均方差** $\sigma_{\text{global}}^2$ |
| **归一化方式** | 归一化到 **当前 batch**                 | 归一化到 **全局分布**                           |
| **计算方式**   | 依赖 mini-batch，可能有波动             | 计算稳定，不依赖 batch size                     |
| **数据变化**   | 每个 batch 统计量不同，训练过程中会波动 | 使用固定的全局统计信息，确保稳定                |

------



## 4. 常见的损失函数



- **逻辑回归损失 / 二元交叉熵损失（Logistic Loss / Binary Cross-Entropy Loss**
  $$
  L(y, \hat{y}) = -\left[y \log(\hat{y}) + (1-y) \log(1-\hat{y})\right]
  $$



- **多分类交叉熵损失（Multiclass Cross-Entropy Loss）**
  $$
  L(y, \hat{y}) = -\sum_{c=1}^C{y_c\log\hat{y}_c}
  $$



- **均方误差（Mean Squared Error, MSE）**
  $$
  \text{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
  $$



- **Bayesian Personalized Ranking (BPR) Loss**

$$
L_{\text{BPR}} = -\sum_{(u, i, j) \in \mathcal{D}} \log \sigma(\hat{y}_{u,i} - \hat{y}_{u,j})
$$

​	其中，$\hat{y}_{u,i}$ 表示用户 $u$ 对正样本 $i$ 的预测得分，$\hat{y}_{u,j} $表示对负样本 $j$ 的预测得分, $\sigma=\frac{1}{1+e^{-x}}$ 是softmax函数。



---



## 5. 深度学习优化函数

深度学习优化算法是用于训练神经网络的关键技术，旨在通过最小化损失函数来调整模型参数。以下是一些常见的优化算法：

1. **梯度下降法（Gradient Descent, GD）**

   - **原理**: 通过计算损失函数关于模型参数的梯度，沿梯度反方向更新参数。

   - **公式**: 
     $$
     \theta_{t+1} = \theta_t - \eta \nabla_\theta J(\theta_t)
     $$
     ​	其中，$\theta$ 是模型参数，$\eta$是学习率，$J(\theta)$ 是损失函数。

   - **缺点**: 计算整个数据集的梯度，计算量大，收敛慢。

2. **随机梯度下降法（Stochastic Gradient Descent, SGD）**

   - **原理**: 每次迭代只使用一个样本计算梯度并更新参数。

   - **公式**:
     $$
     \theta_{t+1} = \theta_t - \eta \nabla_\theta J(\theta_t; x_i, y_i)
     $$
     其中，$(x_i, y_i)$ 是单个样本。

   - **优点**: 计算速度快，适合大规模数据。

   - **缺点**: 更新方向波动大，收敛不稳定。

3. **小批量梯度下降法（Mini-batch Gradient Descent）**

   - **原理**: 每次迭代使用一个小批量样本计算梯度并更新参数。

   - **公式**:
     $$
     \theta_{t+1} = \theta_t - \eta \nabla_\theta J(\theta_t; B_t)
     $$
     其中，$B_t$ 是小批量样本。

   - **优点**: 结合了GD和SGD的优点，计算效率和稳定性较好。

4. **动量法（Momentum）**

   - **原理**: 引入动量项，加速收敛并减少震荡。
   - **公式**:
     $$
     v_{t+1} = \gamma v_t + \eta \nabla_\theta J(\theta_t)
     \\
     \theta_{t+1} = \theta_t - v_{t+1}
     $$
     其中，$\gamma$ 是动量系数。
   - **优点**: 加速收敛，减少震荡。

5. **Nesterov加速梯度法（Nesterov Accelerated Gradient, NAG）**

   - **原理**: 在动量法的基础上，先根据当前动量更新参数，再计算梯度。

   - **公式**:
     $$
     v_{t+1} = \gamma v_t + \eta \nabla_\theta J(\theta_t - \gamma v_t)
     \\
     \theta_{t+1} = \theta_t - v_{t+1}
     $$
     

   - **优点**: 比动量法更快收敛。

6. **自适应学习率算法**

   - **Adagrad**

     - **原理**: 根据参数的历史梯度调整学习率。

     - **公式**:
       $$
       \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \nabla_\theta J(\theta_t)
       $$
       其中，$G_t$是历史梯度的平方和。

     - **优点**: 适合稀疏数据。

     - **缺点**: 学习率逐渐减小，可能过早停止学习。

   - **RMSprop**

     - **原理**: 改进Adagrad，使用指数加权平均代替历史梯度平方和。

     - **公式**:
       $$
       G_t = \gamma G_{t-1} + (1 - \gamma) (\nabla_\theta J(\theta_t))^2
       \\
       \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \nabla_\theta J(\theta_t)
       $$
       

     - **优点**: 解决了Adagrad学习率过快下降的问题。

   - **Adam（Adaptive Moment Estimation）**

     - **原理**: 结合动量和RMSprop，计算梯度的一阶矩和二阶矩估计。

     - **公式**:
       $$
       
       m_t = \beta_1 m_{t-1} + (1 - \beta_1) \nabla_\theta J(\theta_t)
       \\
       v_t = \beta_2 v_{t-1} + (1 - \beta_2) (\nabla_\theta J(\theta_t))^2
       \\
       \hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
       \\
       \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t
       $$
       

     - **优点**: 结合动量和自适应学习率，收敛快且稳定。

